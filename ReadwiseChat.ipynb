{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readwise ( http://readwise.io/ ) is a wonderful app that makes it easy to read \n",
    "books and articles and highight parts of the text that are interesting for later\n",
    "reference or review. I've been using it for a few years and over that time have\n",
    "ammased a huge library of highlights on many topics. I review some random\n",
    "highlights daily, and also sync them as markdown to read in my text editor. But\n",
    "wouldn't it be awesome to chat with an AI that has access to the entire library?\n",
    "\n",
    "... enter Open AI, LangChain, and Chroma ...\n",
    "\n",
    "In this sample, we read the highlights from Readwise using the API, index the\n",
    "highlights with their embeddings for semantic retrieval with the ChromaDB vector\n",
    "database, and connect the vector database to a chat model using LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by installing the dependencies and configuring the setup with\n",
    "an Open AI API key, and the access token for Readwise (yes, if you also use\n",
    "Readwise you can run this with your access token to chat with your\n",
    "highlights library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai chromadb requests tqdm\n",
    "from IPython.display import clear_output ; clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \" ... \" # Replace with you Open AI API key\n",
    "READWISE_ACCESS_TOKEN = \" ... \" # Replace with your Readwise access token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to read the highlights from Readwise using the API. Depending on how\n",
    "many highlights you have this could take a while (about an hour for my library),\n",
    "so when we're done we save everything into a JSON file so that we don't have to do\n",
    "it again. If you need to re-read the highlights just delete readwise.json and re-run\n",
    "this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readwise.json already exists. Exiting cell.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "if os.path.exists('readwise.json'):\n",
    "    print('readwise.json already exists. Exiting cell.')\n",
    "    class StopExecution(Exception):\n",
    "        def _render_traceback_(self):\n",
    "            pass\n",
    "    raise StopExecution\n",
    "\n",
    "def readwise(api_method, **params):\n",
    "    try:\n",
    "        url = 'https://readwise.io/api/v2/{}/'.format(api_method)\n",
    "        response = requests.get(\n",
    "            url, params={**params, 'page_size': 1000},\n",
    "            headers={'Authorization': f'Token {READWISE_ACCESS_TOKEN}'})\n",
    "        if response.status_code == 429:\n",
    "            throttle_seconds = int(response.headers['Retry-After']) * 1.33333\n",
    "            sleep(throttle_seconds)\n",
    "            return readwise(api_method, **params)\n",
    "        return response.json()\n",
    "    except:\n",
    "        print(sys.exc_info())\n",
    "        return {}\n",
    "\n",
    "docs = [\n",
    "     doc for doc\n",
    "     in readwise('books')['results']\n",
    "     if doc['category'] in ['books', 'articles', 'tweets']\n",
    "]\n",
    "\n",
    "for doc in tqdm(docs, desc='Reading document highlights', leave=True):\n",
    "    doc['highlights'] = []\n",
    "    highlights_response = readwise('highlights', book_id=doc['id'])\n",
    "    for highlight in highlights_response['results']:\n",
    "        doc['highlights'].append(highlight)\n",
    "\n",
    "docs = [doc for doc in docs if len(doc['highlights']) > 0]\n",
    "\n",
    "with open('readwise.json', 'w') as f:\n",
    "    json.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readwise.json', 'r') as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the highlights, we need to index them. The Chroma\n",
    "vector store uses ChromaDB to create an index of the highlights, each\n",
    "with its embeddings (created using the Open AI text-ada-002 model)\n",
    "and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "lcdocs = []\n",
    "for doc in docs:\n",
    "  metadata = {\n",
    "      'title': doc['title'] or '',\n",
    "      'author': doc['author'] or '',\n",
    "      'category': doc['category'] or '',\n",
    "      'source_url': doc['source_url'] or '',\n",
    "      'tags': ' '.join(['#' + tag['name'] for tag in doc['tags']]),\n",
    "  }\n",
    "  for highlight in doc['highlights']:\n",
    "      if not highlight['note'].startswith('.h'):\n",
    "        lcdocs.append(Document(page_content=highlight['text'], metadata=metadata))\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=lcdocs, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an index of all our highlights, we can connect it to a chat model\n",
    "using LangChain. We use the RetrievalQA chain, which is preconfigured to answer\n",
    "questions by retrieving relevant documents from the index and using their content\n",
    "to craft a response.\n",
    "\n",
    "We use the GPT-3.5-turbo model, which is fast and inexpensive. If you'd like to\n",
    "experiment with a better model, change `model_name` to `'gpt-4'`. It is slower\n",
    "and more expensive, but can produce superior results when working with complex\n",
    "texts.\n",
    "\n",
    "Not that we are returning the retrieved source documents together with the chat\n",
    "model's response. With that, we can display which documents the highlights are\n",
    "coming from for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "  llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.3, max_tokens=1000),\n",
    "  chain_type=\"stuff\",\n",
    "  retriever=vectordb.as_retriever(), \n",
    "  return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the chain ready, asking a question is easy. We can `qa_chain`, which triggers\n",
    "the complete chain with our questions, figures out what query to run against the\n",
    "document index, inserts the retrieved documents into the chat model's context and\n",
    "then relies on the model to produce an answer.\n",
    "\n",
    "With the list of retrieved highlights, we can collect their metadata, and display\n",
    "the title, author, and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "\n",
    "def ask(question):\n",
    "    response = qa_chain(question)\n",
    "    print('\\n'.join(wrap(response['result'])))\n",
    "    print('\\n-----')\n",
    "    src_docs = {}\n",
    "    for source in response['source_documents']:\n",
    "        src_docs[source.metadata['source_url']] = source\n",
    "    for src_doc in src_docs.values():\n",
    "        print(\n",
    "            ' * ',\n",
    "            src_doc.metadata['title'], ' - ',\n",
    "            src_doc.metadata['author'], ' ',\n",
    "            src_doc.metadata['tags'],\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few questions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor theory is a new approach to fundamental physics that aims\n",
      "to explain not just what happens in the world, but what can and cannot\n",
      "happen. It focuses on the physical processes that can create and\n",
      "transform physical objects, rather than just describing their\n",
      "behavior. In other words, it seeks to understand the laws of physics\n",
      "in terms of what can and cannot be constructed, rather than what can\n",
      "and cannot happen.  One example of constructor theory is the idea of a\n",
      "universal constructor, which is a machine that can build any physical\n",
      "object that can be built from a given set of building blocks. Another\n",
      "example is the concept of a constructor game, which is a game that\n",
      "involves building physical objects according to certain rules and\n",
      "constraints. These games can be used to explore the limits of what can\n",
      "and cannot be constructed in the physical world.  Constructor theory\n",
      "also has implications for other fields, such as biology and computer\n",
      "science. For example, it can help us understand the fundamental limits\n",
      "of what can and cannot be achieved by living organisms, and it can\n",
      "provide insights into the limits of computation and artificial\n",
      "intelligence. Overall, constructor theory is a promising new approach\n",
      "to fundamental physics that has the potential to revolutionize our\n",
      "understanding of the physical world.\n",
      "\n",
      "-----\n",
      " *  The Science of Can and Can't  -  Chiara Marletto   #physics #science\n"
     ]
    }
   ],
   "source": [
    "ask(\"ELIF what is constructor theory and cite a few examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One approach to reducing noise in the judicial system is to implement\n",
      "rules and guidelines, as advocated by Frankel and implemented by the\n",
      "US Sentencing Commission. Other approaches may be better suited to\n",
      "different types of judgments. Some strategies designed to reduce noise\n",
      "may also reduce bias. However, it is important to note that some level\n",
      "of noise may be necessary to prevent wrongdoing and deter individuals\n",
      "from engaging in illegal activities. Additionally, some people argue\n",
      "that a noisy system can allow for the accommodation of new and\n",
      "emerging values.\n",
      "\n",
      "-----\n",
      " *  Noise: A Flaw in Human Judgement  -  Daniel Kahneman, Olivier Sibony, Cass R. Sunstein   #thinking\n"
     ]
    }
   ],
   "source": [
    "ask(\"What are some of the approaches one can take to avoid the detrimental effects of human noise in the judicial system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When trying to increase the price of a product you are selling, you\n",
      "should consider how much value customers attach to your products and\n",
      "services. You should also recognize that your customers perceive the\n",
      "value of your products and services in different ways depending on\n",
      "their specific requirements. If you build these variations into your\n",
      "pricing structure, you can expect to receive higher profits than you\n",
      "would with a single pricing policy. Additionally, you should consider\n",
      "the four ways to increase your business's revenue, which are\n",
      "increasing the number of customers you serve, increasing the average\n",
      "size of each transaction by selling more, increasing the frequency of\n",
      "transactions per customer, and raising your prices. Finally, value\n",
      "comparison is usually the optimal way to price your offer, since the\n",
      "value of an offer to a specific group can be quite high, resulting in\n",
      "a much better price.\n",
      "\n",
      "-----\n",
      " *  The Personal MBA  -  Josh Kaufman   #business\n"
     ]
    }
   ],
   "source": [
    "ask(\"What are some of the considerations when trying to increase the price of a product you are selling?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Various biblical texts suggest that YHWH came from the south; he comes\n",
      "“from Seir,” “from Edom,” or “from Mount Paran.” The idea that the god\n",
      "YHWH has a non-Israelite origin has become the established consensus\n",
      "in scholarly circles, and archaeological discoveries in the Levant and\n",
      "Mesopotamia in the nineteenth century and especially in the twentieth\n",
      "century have suggested a variety of hypotheses about this origin.\n",
      "\n",
      "-----\n",
      " *  The Invention of God  -  Thomas Römer   #bible #history\n"
     ]
    }
   ],
   "source": [
    "ask(\"Where did the god YHWH come from?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
